[
  {
    "name": "_cast",
    "schema": {
      "category": "Custom",
      "description": "Cast input to `dtype`.",
      "attributes": [
        {
          "description": "",
          "name": "dtype", "type": "enum",
          "enum": ["void", "int8", "uint8", "int16", "uint16", "int32", "uint32", "int64", "uint64",
            "float16", "float32", "float64", "pointer", "char8", "char16", "char32",
            "unknown8", "unknown16", "unknown32", "unknown64", "unknown128",
            "bool", "complex32", "complex64", "complex128"]
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_copy",
    "schema": {
      "category": "Custom",
      "description": "Copy input to output.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_dims",
    "schema": {
      "category": "Tensor",
      "description": "Get input tensor's dims.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dims",
          "type": "int32"
        }
      ]
    }
  },
  {
    "name": "_dimshuffle",
    "schema": {
      "category": "Transform",
      "description": "Shuffle value on specific `dim`. \nExample: \n    Do BGR2RGB on NCHW format tensor: dim=1, shuffle = [2, 1, 0].",
      "attributes": [
        {
          "description": "dim in [-x.dims, x.dims).",
          "name": "dim", "type": "int32"
        },
        {
          "description": "shuffle.size >= 1.",
          "name": "shuffle", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_dragon_conv2d_padding",
    "schema": {
      "category": "Custom",
      "description": "Dragon dynamic padding.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "method in [VALID, SAME_UPPER, SAME_LOWER]",
          "name": "padding_method", "type": "string", "default": "VALID"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_dragon_pooling2d_padding",
    "schema": {
      "category": "Custom",
      "description": "Dragon dynamic padding.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "ceil", "type": "bool", "default": true
        }
      ],
      "inputs": [
        {
          "description": "[device] Compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_expand",
    "schema": {
      "category": "Shape",
      "description": "Return x if dims <= x.dims, else expanded x shape to has dims. First insert front of shape if `inverse` is false.",
      "attributes": [
        {
          "description": "max dim can be add in front.",
          "name": "front", "type": "int32"
        },
        {
          "description": "max dim can be add in end.",
          "name": "end", "type": "int32"
        },
        {
          "description": "first add in front if inverse is false.",
          "name": "inverse", "type": "bool", "default": false
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_limit",
    "schema": {
      "category": "Custom",
      "description": "y = x if x.shape < `shape`, else center crop x.  \nNote: If shape.size < x.dims, then expand -1 on the x's high dim. \nExample: \n    if x=float32[1, 3, 90, 90], shape=[-1, -1, 80, 80], got y=[1, 3, 80, 80].",
      "attributes": [
        {
          "description": "shape limit, -1 for un-limited dim.",
          "name": "shape", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_mx_pooling2d_padding",
    "schema": {
      "category": "Custom",
      "description": "MXNet dynamic padding.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "valid", "type": "bool"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_nhwc_center_crop2d",
    "schema": {
      "category": "Custom",
      "description": "Center crop tensor from given NHWC format tensor.",
      "attributes": [
        {
          "description": "{width, height}",
          "name": "size", "type": "int32[2]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "[N, H, W, C]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, size(1), size(0), C]"
        }
      ]
    }
  },
  {
    "name": "_nhwc_letterbox",
    "schema": {
      "category": "Custom",
      "description": "Adjust image within letterbox, resize image and pad with outer_value.",
      "attributes": [
        {
          "description": "{width, height}",
          "name": "size", "type": "int32[1] or int32[2]"
        },
        {
          "description": "resize image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum",
          "enum": ["linear", "cubic", "nearest", "hard"]
        },
        {
          "description": "outer value pad image after reiszed.",
          "name": "outer_value", "type": "float32", "default": 0
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "[N, H, W, C]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, size(1), size(0), C]"
        }
      ]
    }
  },
  {
    "name": "_nhwc_scale_resize2d",
    "schema": {
      "category": "Tensor",
      "description": "Equal scale or hard resize imagel. If size.size == 1, do equal scale image with long edge. If size.size == 2, do hard resize image.",
      "attributes": [
        {
          "description": "{width, height}",
          "name": "size", "type": "int32[1] or int32[2]"
        },
        {
          "description": "resize image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum",
          "enum": ["linear", "cubic", "nearest", "hard"]
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "[N, H, W, C]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, C]"
        }
      ]
    }
  },
  {
    "name": "_onnx_pooling2d_padding",
    "schema": {
      "category": "Custom",
      "description": "ONNX dynamic auto padding.",
      "attributes": [
        {
          "description": "in [NOTSET, SAME_UPPER, SAME_LOWER, VALID].",
          "name": "auto_pad", "type": "string", "default": "NOTSET"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_reshape",
    "schema": {
      "category": "Shape",
      "description": "Reshape tensor.",
      "attributes": [
        {
          "description": "dest shape, -1 for remaining unspecified dimensions, 0 for equal to input dim.",
          "name": "shape", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_reshape_v2",
    "schema": {
      "category": "Shape",
      "description": "Reshape tensor.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host] dest shape, -1 for remaining unspecified dimensions, 0 for equal to input dim.",
          "name": "shape",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_resize2d",
    "schema": {
      "category": "Tensor",
      "description": "Resize tensor to given size, only 2d resize support. Output tensor has shape `size`. s\nNote: x.dims == size.size. \nExample: \n    x=[1, 640, 480, 3], size=[-1, 300, 300, -1], ",
      "attributes": [
        {
          "description": "resize image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum", "default": "linear",
          "enum": ["linear", "cubic", "nearest", "hard"]
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "size",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_shape",
    "schema": {
      "category": "Tensor",
      "description": "Get input tensor's shape.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "shape",
          "type": "int32[_]"
        }
      ]
    }
  },
  {
    "name": "_tf_conv2d_padding",
    "schema": {
      "category": "Custom",
      "description": "TensorFlow dynamic padding.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "method in [VALID, SAME]",
          "name": "padding_method", "type": "string"
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_tf_pooling2d_padding",
    "schema": {
      "category": "Custom",
      "description": "TensorFlow dynamic padding.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "method in [VALID, SAME]",
          "name": "padding_method", "type": "string"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        }
      ],
      "inputs": [
        {
          "description": "[device] Compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "dynamic_padding",
          "type": "int32[4, 2]"
        }
      ]
    }
  },
  {
    "name": "_transpose",
    "schema": {
      "category": "Transform",
      "description": "Transpose tenosr with `permute`, like y = numpy.transpose(x, permute)",
      "attributes": [
        {
          "description": "permute.size == x.dims.",
          "name": "permute", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "abs",
    "schema": {
      "category": "Tensor",
      "description": "y = abs(x)",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "add",
    "schema": {
      "category": "Tensor",
      "description": "y = lhs + rhs. Support broadcast.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "lhs",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "rhs",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] lhs + rhs",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "add_bias",
    "schema": {
      "category": "Normalization",
      "description": "Add bias on `dim`. Broadcast add. b.size == x.shape(dim)",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "in [-x.dims, x.dims)",
          "name": "dim", "type": "int32", "default": 1
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "b",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "affine_smaple2d",
    "schema": {
      "category": "Tensor",
      "description": "Sample 2d data on x: y([a, b]) = sample(x(affine * [a, b, 1])). \n`dim` and `dim + 1` mean image's dimensions.",
      "attributes": [
        {
          "description": "resize image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum",
          "enum": ["linear", "cubic", "nearest", "hard"]
        },
        {
          "description": "in [-x.dims, x.dims)",
          "name": "dim", "type": "int32", "default": -2
        },
        {
          "description": "sampled value if sample on the over area.",
          "name": "outer_value", "type": "float", "default": 0
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "argmax",
    "schema": {
      "category": "Tensor",
      "description": "Get max indices in x on `dim`. Indices has dim = x.dims - 1, shape like [x.shape(0), ..., x.shape(dim - 1), x.shape(dim + 1), ...]",
      "attributes": [
        {
          "description": "in [-x.dims, x.dims)",
          "name": "dim", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "indices",
          "type": "int32[...]"
        }
      ]
    }
  },
  {
    "name": "batch_norm",
    "schema": {
      "category": "Normalization",
      "description": "y = (x - mean) / (sqrt(variance + epsilon))",
      "attributes": [
        {
          "description": "data channel, in [-x.dims, x.dims)",
          "name": "dim", "type": "int32", "default": 1
        },
        {
          "description": "incase of divide zero.",
          "name": "epsilon", "type": "float32", "default": 1e-5
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device] mean.size == x.shape(dim)",
          "name": "mean",
          "type": "array"
        },
        {
          "description": "[device] variance.size == x.shape(dim)",
          "name": "variance",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "batch_scale",
    "schema": {
      "category": "Normalization",
      "description": "y = x * scale + bias",
      "attributes": [
        {
          "description": "data channel, in [-x.dims, x.dims)",
          "name": "dim", "type": "int32", "default": 1
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device] scale.size == x.shape(dim)",
          "name": "scale",
          "type": "array"
        },
        {
          "description": "[device] bias.size == x.shape(dim)",
          "name": "bias",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "batch_to_space4d",
    "schema": {
      "category": "Transform",
      "description": "Rearranges (permutes) data from batch into blocks of spatial data, followed by cropping. Only support NCHW format. \n See tf.[BatchToSapceND](https://www.w3cschool.cn/tensorflow_python/tensorflow_python-bnyg2ckl.html) for more information.",
      "attributes": [
        {
          "description": "[[crop_top, crop_bottom], [crop_left, crop_right]]",
          "name": "crop", "type": "int32[2, 2]"
        },
        {
          "description": "[block_height, block_width]",
          "name": "block_shape", "type": "int32[2]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ],
      "examples": [
        {
          "summary": "output shape",
          "code" : "output_shape[0] = input_shape[0] / (block_height * block_width);\noutput_shape[2] = input_shape[2] * block_height - crop_top - crop_bottom;\noutput_shape[3] = input_shape[3] * block_width - crop_left - crop_right;\noutput_shape[1] = input_shape[1];"
        }
      ]
    }
  },
  {
    "name": "broadcast",
    "schema": {
      "category": "Tensor",
      "description": "Broadcast x to shape, assume like x * numpy.ones(shape).",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "shape",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "chunk",
    "schema": {
      "category": "Transform",
      "description": "Inverse operation of concat. Assume like y = numpy.split(x, chunks, dim).",
      "attributes": [
        {
          "description": "number to split on dim.",
          "name": "chunks", "type": "int32"
        },
        {
          "description": "axis to split.",
          "name": "dim", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "chunks",
          "type": "list[tensor]",
          "option": "variadic"
        }
      ]
    }
  },
  {
    "name": "concat",
    "schema": {
      "category": "Transform",
      "description": "Concat all input tensors.",
      "attributes": [
        {
          "description": "axis to concat.",
          "name": "dim", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device] list of tensors",
          "name": "tensors",
          "type": "list[tensor]",
          "option": "variadic"
        }
      ],
      "outputs": [
        {
          "description": "[device] output tensor",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "conv2d",
    "schema": {
      "category": "Layer",
      "description": "2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom; \npad_w = pad_w_left + pad_h_right; \noutput_h = floor((height + pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1); \noutput_w = floor((width + pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "conv2d_quantized",
    "schema": {
      "category": "Layer",
      "description": "Quantized 2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "how to dequantize after convolution. dequantize_scales.size == w.shape(0)",
          "name": "dequantize_scales", "type": "float32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "int8[N, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "int8[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "float32[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom; \npad_w = pad_w_left + pad_h_right; \noutput_h = floor((height + pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1); \noutput_w = floor((width + pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "conv2d_v2",
    "schema": {
      "category": "Layer",
      "description": "2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[host] dynamic padding.",
          "name": "padding",
          "type": "int32[4, 2]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom; \npad_w = pad_w_left + pad_h_right; \noutput_h = floor((height + pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1); \noutput_w = floor((width + pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "dcn_v2_forward",
    "schema": {
      "category": "Layer",
      "description": "DCN v2, see [DCNv2](https://github.com/CharlesShang/DCNv2) for more infromation.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "deformable_groups", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[device] convolution bias: [output_channels].",
          "name": "b",
          "type": "[_]"
        },
        {
          "description": "[device]",
          "name": "offset",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "mask",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ]
    }
  },
  {
    "name": "depthwise_conv2d",
    "schema": {
      "category": "Layer",
      "description": "Depthwise 2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [multiplier_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device] output_channel = multiplier_channels * input_channels",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom; \npad_w = pad_w_left + pad_h_right; \noutput_h = floor((height + pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1); \noutput_w = floor((width + pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "depthwise_conv2d_v2",
    "schema": {
      "category": "Layer",
      "description": "Depthwise 2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[host] dynamic padding.",
          "name": "padding",
          "type": "int32[4, 2]"
        },
        {
          "description": "[device] convolution kernel: [multiplier_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device] output_channel = multiplier_channels * input_channels",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom; \npad_w = pad_w_left + pad_h_right; \noutput_h = floor((height + pad_h - (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1); \noutput_w = floor((width + pad_w - (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "div",
    "schema": {
      "category": "Tensor",
      "description": "y = lhs / rhs. Support broadcast.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "lhs",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "rhs",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] lhs / rhs",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "divided",
    "schema": {
      "category": "Custom",
      "description": "Adjust input x' shape to witch can be divide exactly.",
      "attributes": [
        {
          "description": "-1 for no adjustment, size.size == x.dims.",
          "name": "size", "type": "int32[_]"
        },
        {
          "description": "padding value when pad input tensor.",
          "name": "padding_value", "type": "float", "default": 0
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "exp",
    "schema": {
      "category": "Tensor",
      "description": "y = exp(x)",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "flatten",
    "schema": {
      "category": "Shape",
      "description": "Flatten tensor. Reduction axes after `dim`",
      "attributes": [
        {
          "description": "reduction axes after `dim`.",
          "name": "dim", "type": "int32", "default": 1
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "force_color",
    "schema": {
      "category": "Custom",
      "description": "Force convert input data to color mode. Assume that channel is last dim.",
      "attributes": [
        {
          "description": "reduction axes after `dim`.",
          "name": "dims", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "[..., C]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[..., 3]"
        }
      ]
    }
  },
  {
    "name": "force_gray",
    "schema": {
      "category": "Custom",
      "description": "Force convert input data to gray mode. Assume that channel is last dim.",
      "attributes": [
        {
          "description": "How to convert color format to gray, y = [b, g, r] * scale. [0.114, 0.587, 0.299] is for bgr2gray.",
          "name": "scale", "type": "float32[_]", "default": [0.114, 0.587, 0.299]
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "[..., C]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[..., 3]"
        }
      ]
    }
  },
  {
    "name": "fused_batch_norm",
    "schema": {
      "category": "Normalization",
      "description": "y = batch_scale(batch_norm(x, mean, variance), scale, bias)",
      "attributes": [
        {
          "description": "data channel, in [-x.dims, x.dims)",
          "name": "dim", "type": "int32", "default": 1
        },
        {
          "description": "incase of divide zero.",
          "name": "epsilon", "type": "float32", "default": 1e-5
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device] mean.size == x.shape(dim)",
          "name": "mean",
          "type": "array"
        },
        {
          "description": "[device] variance.size == x.shape(dim)",
          "name": "variance",
          "type": "array"
        },
        {
          "description": "[device] scale.size == x.shape(dim)",
          "name": "scale",
          "type": "array"
        },
        {
          "description": "[device] bias.size == x.shape(dim)",
          "name": "bias",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "gather",
    "schema": {
      "category": "Transform",
      "description": "y = numpy.take(x, indices, axis=axis)",
      "attributes": [
        {
          "description": "",
          "name": "axis", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "indices",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "gatherv2",
    "schema": {
      "category": "Transform",
      "description": "Index the last axis (if indices.shape[-1] == x.rank) or slice (indices.shape[-1] < x.rank) according to the indices.shape[-1]. \nOutput Shape indices.shape[:-1] + x.shape[indices.shape[-1]:].",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "indices",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "gemm",
    "schema": {
      "category": "Layer",
      "description": "Do gemm(transA, transB, M, N, K, alpha, a, _, b, _, beta, C, _).",
      "attributes": [
        {
          "description": "",
          "name": "alpha", "type": "float", "default": 1
        },
        {
          "description": "",
          "name": "beta", "type": "float", "default": 1
        },
        {
          "description": "",
          "name": "transA", "type": "bool", "default": false
        },
        {
          "description": "",
          "name": "transB", "type": "bool", "default": false
        }
      ],
      "inputs": [
        {
          "description": "[device] transA ? [K, M] : [M, K]",
          "name": "a",
          "type": "matrix"
        },
        {
          "description": "[device] transB ? [N, K] : [K, N]",
          "name": "b",
          "type": "matrix"
        },
        {
          "description": "[device] can be broadcast to [M, N]",
          "name": "c",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device] [M, N]",
          "name": "y",
          "type": "matrix"
        }
      ],
      "examples": [
        {
          "code": "A' = transpose(A) if transA else A\nB' = transpose(B) if transB else B\nCompute Y = alpha * A' * B' + beta * C,\nwhere input tensor A has shape (M, K) or (K, M),\ninput tensor B has shape (K, N) or (N, K),\ninput tensor C is broadcastable to shape (M, N),\nand output tensor Y has shape (M, N).\nA will be transposed before doing the computation\nif attribute transA is non-zero, same for B and transB.\nThis operator supports unidirectional broadcasting\n(tensor C should be unidirectional broadcastable\nto tensor A * B); \n",
          "summary": ""
        }
      ]
    }
  },
  {
    "name": "global_pooling2d",
    "schema": {
      "category": "Pool",
      "description": "Global pooling.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "type", "type": "enum",
          "enum": ["max", "avg"]
        }
      ],
      "inputs": [
        {
          "description": "[device] Compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ]
    }
  },
  {
    "name": "inner_prod",
    "schema": {
      "category": "Layer",
      "description": "Do y = x \\times w",
      "attributes": [
        {
          "description": "if transpose on w before \\times.",
          "name": "transpose", "type": "bool", "default": false
        }
      ],
      "inputs": [
        {
          "description": "[device] flatten x if x.dims > 2.",
          "name": "x",
          "type": "matrix"
        },
        {
          "description": "[device]",
          "name": "w",
          "type": "matrix"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "matrix"
        }
      ]
    }
  },
  {
    "name": "l2_norm",
    "schema": {
      "category": "Normalization",
      "description": "Do L2 norm on `dim` axis. \nFor 1-D NDArray, it computes: out = data / sqrt(sum(data ** 2) + eps). \n For N-D NDArray, if the input array has shape (N, N, ..., N): \nfor dim in 2...N \nfor i in 0...N \nout[.....,i,...] = take(out, indices=i, axis=dim) / sqrt(sum(take(out, indices=i, axis=dim) ** 2) + eps)",
      "attributes": [
        {
          "description": "data channel, in [-x.dims, x.dims)",
          "name": "dim", "type": "int32"
        },
        {
          "description": "incase of divide zero.",
          "name": "epsilon", "type": "float32", "default": 1e-5
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "leaky_relu",
    "schema": {
      "category": "Activation",
      "description": "y = x > 0 ? x : scale * x",
      "attributes": [
        {
          "description": "",
          "name": "scale", "type": "float32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "max",
    "schema": {
      "category": "Tensor",
      "description": "Got max value of x on `dim` axis.",
      "attributes": [
        {
          "description": "",
          "name": "dim", "type": "int32"
        },
        {
          "description": "if retain reduced dimensions with length 1.",
          "name": "keep_dims", "type": "bool", "default": true
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] `[x.shape[:dim], 1, x.shape[dim+1:]]` if `keep_dims` else `[x.shape[:dim], x.shape[dim+1:]]`",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "maximum",
    "schema": {
      "category": "Tensor",
      "description": "y = max(lhs, rhs). Support broadcast.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "lhs",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "rhs",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] max(lhs, rhs)",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "mul",
    "schema": {
      "category": "Tensor",
      "description": "`y = lhs \\mul rhs`. Support broadcast.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "lhs",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "rhs",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] `lhs \\mul rhs`",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "non_max_suppression_v3",
    "schema": {
      "category": "Tensor",
      "description": "`y = lhs \\mul rhs`. Support broadcast.",
      "attributes": [
        {
          "description": "output bbox number, <= `N`",
          "name": "max_output_size", "type": "int32"
        },
        {
          "description": "min overlap area to select bbox to fuse.",
          "name": "iou_threshold", "type": "float"
        },
        {
          "description": "threshold for deciding when to remove boxes based on score.",
          "name": "score_threshold", "type": "float"
        },
        {
          "description": "in [xyxy, xywh], representing bbox area",
          "name": "mode", "type": "string", "default": "xyxy"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "bbox",
          "type": "[N, 4]"
        },
        {
          "description": "[device]",
          "name": "socres",
          "type": "[N]"
        }
      ],
      "outputs": [
        {
          "description": "[device] selected indices, -1 for no selection.",
          "name": "y",
          "type": "int32[_]"
        }
      ]
    }
  },
  {
    "name": "norm_image",
    "schema": {
      "category": "Normalization",
      "description": "Norm image with mean and std_dev. For each $x_i$ of n-th image run$x_i = (x_i - mean(x_i)) / (std_dev(x_i) + epsilon)$.",
      "attributes": [
        {
          "description": "incase of divide zero.",
          "name": "epsilon", "type": "float32", "default": 1e-5
        }
      ],
      "inputs": [
        {
          "description": "[device] first axes represent value has N images.",
          "name": "x",
          "type": "[N, ...]"
        }
      ],
      "outputs": [
        {
          "description": "[device] normalized images.",
          "name": "y",
          "type": "[N, ...]"
        }
      ]
    }
  },
  {
    "name": "pad",
    "schema": {
      "category": "Tensor",
      "description": "Pad `padding_value` on input tensor. Support neg `padding` for crop tensor.",
      "attributes": [
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host] K == x.dims",
          "name": "padding",
          "type": "int32[K, 2]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "pooling2d",
    "schema": {
      "category": "Pool",
      "description": "2D pooling.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "in [max=0, avg=1]",
          "name": "type", "type": "enum",
          "enum": ["max", "avg"]
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "in [black=0, copy=1, loop=2, white=3]. Black for caffe style. White for dragon style (fixed denominator for avg).",
          "name": "padding_type", "type": "enum", "default": "black",
          "enum": ["black", "copy", "loop", "white"]
        },
        {
          "description": "",
          "name": "ksize", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] Compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ]
    }
  },
  {
    "name": "pooling2d_v2",
    "schema": {
      "category": "Pool",
      "description": "2D pooling.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "in [max=0, avg=1]",
          "name": "type", "type": "enum",
          "enum": ["max", "avg"]
        },
        {
          "description": "in [black=0, copy=1, loop=2, white=3]. Black for caffe style. White for onnx default style (fixed denominator for avg).",
          "name": "padding_type", "type": "enum", "default": "black",
          "enum": ["black", "copy", "loop", "white"]
        }
      ],
      "inputs": [
        {
          "description": "[device] Compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[host] padding edge.",
          "name": "padding",
          "type": "int32[4, 2]"
        },
        {
          "description": "[host] pooling kernel size.",
          "name": "ksize",
          "type": "int32[4]"
        },
        {
          "description": "[host] pooling stirde.",
          "name": "stride",
          "type": "int32[4]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ]
    }
  },
  {
    "name": "prelu",
    "schema": {
      "category": "Activation",
      "description": "y = x > 0 ? x : slope * x",
      "attributes": [
        {
          "description": "dimension of slope.",
          "name": "dim", "type": "int32", "default": 1
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device] array.size == x.shape(dim).",
          "name": "slope",
          "type": "array"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "prewhiten",
    "schema": {
      "category": "Normalization",
      "description": "Prewhiten images.",
      "attributes": [
        {
          "description": "incase of divide zero.",
          "name": "epsilon", "type": "float32", "default": 1e-5
        }
      ],
      "inputs": [
        {
          "description": "[device] first axes represent value has N images.",
          "name": "x",
          "type": "[N, ...]"
        }
      ],
      "outputs": [
        {
          "description": "[device] prewhiten images.",
          "name": "y",
          "type": "[N, ...]"
        }
      ],
      "examples": [
        {
          "code": "template <typename T>\nvoid prewhiten(T *data, size_t len)\n{\n    double mean = 0;\n    double std_dev = 0;\n    T *at= nullptr;\n\n    at = data;\n    for (size_t i = 0; i < len; ++i, ++at) mean += *at;\n    mean /= len;\n\n    at = data;\n    for (size_t i = 0; i < len; ++i, ++at) std_dev += (*at - mean) * (*at - mean);\n    std_dev = std::sqrt(std_dev / len);\n    std_dev = std::max<T>(std_dev, 1 / std::sqrt(len));\n    double std_dev_rec = 1 / std_dev;\n\n    at = data;\n    for (size_t i = 0; i < len; ++i, ++at) {\n        *at -= mean;\n        *at *= std_dev_rec;\n    }\n}\n",
          "summary": "implementation example"
        }
      ]
    }
  },
  {
    "name": "proposal",
    "schema": {
      "category": "Tensor",
      "description": "See [Dragon proposal](http://dragon.seetatech.com/api/python/contents/operators/contrib/rcnn).",
      "attributes": [
        {
          "description": "The strides of anchors.",
          "name": "strides", "type": "int32[_]"
        },
        {
          "description": "The ratios of anchors.",
          "name": "ratios", "type": "float32[_]"
        },
        {
          "description": "The scales of anchors.",
          "name": "scales", "type": "float32[_]"
        },
        {
          "description": "The number of anchors before nms.",
          "name": "pre_nms_top_n", "type": "int32", "default": 6000
        },
        {
          "description": "The number of anchors after nms.",
          "name": "post_nms_top_n", "type": "int32", "default": 300
        },
        {
          "description": "The threshold of nms.",
          "name": "nms_thresh", "type": "float32", "default": 0.7
        },
        {
          "description": "The min size of anchors.",
          "name": "min_size", "type": "int32", "default": 16
        },
        {
          "description": "Finest level of the FPN pyramid.",
          "name": "min_level", "type": "int32", "default": 2
        },
        {
          "description": "Coarsest level of the FPN pyramid.",
          "name": "max_level", "type": "int32", "default": 5
        },
        {
          "description": "The baseline scale of mapping policy.",
          "name": "canonical_scale", "type": "int32", "default": 224
        },
        {
          "description": "Heuristic level of the canonical scale.",
          "name": "canonical_level", "type": "int32", "default": 4
        }
      ],
      "inputs": [
        {
          "description": "[device] list[scores], length like strides",
          "name": "inputs",
          "type": "list[tensor]",
          "option": "variadic"
        },
        {
          "description": "[device] [1, A, 4, K], A = number of anchors, K = feature map's height * width",
          "name": "prob",
          "type": "tensor"
        },
        {
          "description": "[device] [1, A, K], A = number of anchors, K = feature map's height * width",
          "name": "bbox",
          "type": "tensor"
        },
        {
          "description": "[host] conatins [H, W, scale]. `H` and `W is input image size. `scale` is they scale value between input image and orignal image.",
          "name": "im_info",
          "type": "float32[3]"
        }
      ],
      "outputs": [
        {
          "description": "[device] The propsals. Shape is [N * post_nms_top_n, 5], N = number of images.",
          "name": "proposals",
          "type": "[_, 5]"
        }
      ]
    }
  },
  {
    "name": "quantize",
    "schema": {
      "category": "Custom",
      "description": "quantize input tensor.",
      "attributes": [
        {
          "description": "assume that quantize_scale.size == x.shape(0)",
          "name": "quantize_scale", "type": "float32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[host]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[host]",
          "name": "y",
          "type": "int8[...]"
        }
      ]
    }
  },
  {
    "name": "range",
    "schema": {
      "category": "Custom",
      "description": "Generate a sequence of numbers starting at `start` and extending `delta` increments to a sequence that does not include a `limit`",
      "attributes": [],
      "inputs": [
        {
          "description": "[host] start of the sequence.",
          "name": "start",
          "type": "scalar"
        },
        {
          "description": "[host] end of the sequence, [start, limit)",
          "name": "limit",
          "type": "scalar"
        },
        {
          "description": "[host] step of the sequence.",
          "name": "delta",
          "type": "scalar"
        }
      ],
      "outputs": [
        {
          "description": "[device] sequence",
          "name": "array",
          "type": "array"
        }
      ]
    }
  },
  {
    "name": "reduce_mean",
    "schema": {
      "category": "Tensor",
      "description": "Computes the mean of the input tensor's element along the provided axes. The resulted\ntensor has the same rank as the input if keepdims equal 1. If keepdims equal 0, then\nthe resulted tensor have the reduced dimension pruned.\n\nThe above behavior is similar to numpy, with the exception that numpy default keepdims to\nFalse instead of True.",
      "attributes": [
        {
          "description": "A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. All elements need to be adjacent for this version.",
          "name": "dims", "type": "int32[_]",
          "required": true
        },
        {
          "description": "Keep the reduced dimension or not, default 1 mean keep reduced dimension.",
          "name": "keep_dims", "type": "bool", "default": true
        }
      ],
      "inputs": [
        {
          "description": "[device] input tensor.",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] reduced tensor.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "reduce_sum",
    "schema": {
      "category": "Tensor",
      "description": "Computes the sum of the input tensor's element along the provided axes. The resulted\ntensor has the same rank as the input if keepdims equal 1. If keepdims equal 0, then\nthe resulted tensor have the reduced dimension pruned.\n\nThe above behavior is similar to numpy, with the exception that numpy default keepdims to\nFalse instead of True.",
      "attributes": [
        {
          "description": "A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. dims.size must be 1 for this version.",
          "name": "dims", "type": "int32[_]",
          "required": true
        },
        {
          "description": "Keep the reduced dimension or not, default 1 mean keep reduced dimension.",
          "name": "keep_dims", "type": "bool", "default": true
        }
      ],
      "inputs": [
        {
          "description": "[device] input tensor.",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] reduced tensor.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "relu",
    "schema": {
      "category": "Activation",
      "description": "y = x > 0 ? x : 0",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "relu_max",
    "schema": {
      "category": "Activation",
      "description": "y = min(x > 0 ? x : 0, max)",
      "attributes": [
        {
          "description": "max value to clip.",
          "name": "max", "type": "float32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "resize_nearest_neighbor",
    "schema": {
      "category": "Tensor",
      "description": "Resize tensor to given size, only 2d resize support. Resize on [dim, dim + 1]. Reisze by nearest.",
      "attributes": [
        {
          "description": "Oh hard to describe.",
          "name": "align_corners", "type": "bool", "default": false
        },
        {
          "description": "resize on [dim, dim + 1].",
          "name": "dim", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "size",
          "type": "int32[2]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "roi_align",
    "schema": {
      "category": "Tensor",
      "description": "See [Dragon ROIAlign](http://dragon.seetatech.com/api/python/contents/operators/vision#dragon.operators.vision.ROIAlign). features and proposal are same shape.",
      "attributes": [
        {
          "description": "The height of pooled tensor.",
          "name": "pool_h", "type": "int32", "default": 0
        },
        {
          "description": "The width of pooled tensor.",
          "name": "pool_w", "type": "int32", "default": 0
        },
        {
          "description": "The `inverse` of total down-sampling multiples on input tensor.",
          "name": "spatial_scale", "type": "float32", "default": 1.0
        },
        {
          "description": "The number of sampling grids for each RoI bin.",
          "name": "sampling_ratio", "type": "int32", "default": 2
        }
      ],
      "inputs": [
        {
          "description": "[device] Features, represent as [N, C, H, W] format",
          "name": "features",
          "type": "tensor"
        },
        {
          "description": "[device] RoIs, represent as [num_rois, 5] format, this last axis layout [batch_index, min_x, min_y, max_x, max_y] respectively.",
          "name": "proposal",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] The batch of pooled RoI regions. Shape is [proposal.shape(0), features.size(1), pool_h, pool_w]",
          "name": "regions",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "rsqrt",
    "schema": {
      "category": "Tensor",
      "description": "y = 1 / sqrt(x)",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "sample2d",
    "schema": {
      "category": "Tensor",
      "description": "Sample 2d on input tensor, assume that image [height, width] is [dim, dim + 1].",
      "attributes": [
        {
          "description": "sample image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum", "default": "nearest",
          "enum": ["linear", "cubic", "nearest", "hard"]
        },
        {
          "description": "[dim, dim + 1] for image.",
          "name": "dim", "type": "int32", "default": "-2"
        },
        {
          "description": "",
          "name": "scale", "type": "float32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] the output shape $output_i = floor(input_i * scale)$.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "sample2d_v2",
    "schema": {
      "category": "Tensor",
      "description": "Sample 2d on input tensor, assume that image [height, width] is [dim, dim + 1].",
      "attributes": [
        {
          "description": "sample image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum", "default": "nearest",
          "enum": ["linear", "cubic", "nearest", "hard"]
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host] scale.size == x.dims.",
          "name": "scale",
          "type": "float32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device] the output shape $output_i = floor(input_i * scale_i)$.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "shape_index_patch",
    "schema": {
      "category": "Transform",
      "description": "Get crop [x_patch_h, x_patch_w] on x, according to pos. pos.number == x.number.",
      "attributes": [
        {
          "description": "sample image method, in [linear=0, cubic=1, nearest=2, hard=3].",
          "name": "type", "type": "enum", "default": "nearest",
          "enum": ["linear", "cubic", "nearest", "hard"]
        }
      ],
      "inputs": [
        {
          "description": "[device] shape is [number, channels, height, width]",
          "name": "x",
          "type": "[_, _, _, _]"
        },
        {
          "description": "[device] shape is [number, landmark, 1, 1].",
          "name": "pos",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device] output shape is [number, channels, x_patch_h, landmark / 2, x_patch_w], x_patch_h = int(origin_patch.h * x.height / origin.h + 0.5), x_patch_w = int(origin_patch.w * x.width / origin.w + 0.5).",
          "name": "y",
          "type": "[_, _, _, _, _]"
        }
      ]
    }
  },
  {
    "name": "sigmoid",
    "schema": {
      "category": "Activation",
      "description": "y = 1 / (1 + exp(-x))",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "slice",
    "schema": {
      "category": "Tensor",
      "description": "Slice input tensor. y = x[begin: begin + size].",
      "attributes": [
        {
          "description": "begin.size == x.dims",
          "name": "begin", "type": "int32[_]"
        },
        {
          "description": "size.size == x.dims",
          "name": "size", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == size.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "slice_v2",
    "schema": {
      "category": "Tensor",
      "description": "Slice input tensor. y = x[begin: begin + size].",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host] begin.size == x.dims",
          "name": "begin",
          "type": "int32[_]"
        },
        {
          "description": "[host] size.size == x.dims",
          "name": "size",
          "type": "int32[_]"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == size.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "slice_v3",
    "schema": {
      "category": "Tensor",
      "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy: https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html. See onnx.[Slice](https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice).",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "starts",
          "type": "int32[_]"
        },
        {
          "description": "[host]",
          "name": "ends",
          "type": "int32[_]"
        },
        {
          "description": "[host]",
          "name": "axes",
          "type": "int32[_]",
          "option": "optional"
        },
        {
          "description": "[host]",
          "name": "steps",
          "type": "int32[_]",
          "option": "optional"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "softmax",
    "schema": {
      "category": "Activation",
      "description": "If not smooth: $y_i = exp(x_i) / \\sum{exp(x_i)}$. ",
      "attributes": [
        {
          "description": "softmax dimension",
          "name": "dim", "type": "int32", "default": 1
        },
        {
          "description": "If do smooth softmax.",
          "name": "smooth", "type": "bool", "default": true
        }
      ],
      "inputs": [
        {
          "description": "[device] input tensor.",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] reduced tensor.",
          "name": "y",
          "type": "tensor"
        }
      ],
      "examples" : [
        {
          "summary": "smooth = false",
          "code": "y_i = exp(x_i) / \\sum{exp(x_i)}"
        },
        {
          "summary": "smooth = true",
          "code": "t_i = x_i - max(x) \nt_i = x_i - max(x)"
        }
      ]
    }
  },
  {
    "name": "space_to_batch4d",
    "schema": {
      "category": "Transform",
      "description": "This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\ngrid of blocks of shape `block_shape`, and interleaves these blocks with the\n\"batch\" dimension (0) such that in the output, the spatial dimensions\n`[1, ..., M]` correspond to the position within the grid, and the batch\ndimension combines both the position within a spatial block and the original\nbatch position. Only support NCHW format. \n See tf.[BatchToSapceND](https://www.w3cschool.cn/tensorflow_python/tensorflow_python-wygr2kbg.html) for more information.",
      "attributes": [
        {
          "description": "[[padding_top, padding_bottom], [padding_left, padding_right]]",
          "name": "padding", "type": "int32[2, 2]"
        },
        {
          "description": "[block_height, block_width]",
          "name": "block_shape", "type": "int32[2]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ],
      "examples": [
        {
          "summary": "output shape",
          "code" : "output_shape[0] = input_shape[0] * block_height * block_width;\noutput_shape[2] = (input_shape[2] + padding_top + padding_bottom) / block_height;\noutput_shape[3] = (input_shape[3] + padding_left + padding_right) / block_width;\noutput_shape[1] = input_shape[1];"
        }
      ]
    }
  },
  {
    "name": "sqrt",
    "schema": {
      "category": "Tensor",
      "description": "y = sqrt(x)",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "square",
    "schema": {
      "category": "Tensor",
      "description": "y = x ** 2",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "squeeze",
    "schema": {
      "category": "Shape",
      "description": "Remove dimensions witch equals to 1.",
      "attributes": [
        {
          "description": "axes to remove. if axes not set, then remove all dim equals to 1.",
          "name": "axes", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "stack",
    "schema": {
      "category": "Transform",
      "description": "Equals to numpy.stack.",
      "attributes": [
        {
          "description": "axis to stack.",
          "name": "axis", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device] list of tensors",
          "name": "tensors",
          "type": "list[tensor]",
          "option": "variadic"
        }
      ],
      "outputs": [
        {
          "description": "[device] output tensor",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "strided_slice",
    "schema": {
      "category": "Tensor",
      "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy: https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html. See tf.[strided_slice]().",
      "attributes": [
        {
          "description": "",
          "name": "begin", "type": "int32[_]"
        },
        {
          "description": "",
          "name": "end", "type": "int32[_]"
        },
        {
          "description": "",
          "name": "stride", "type": "int32[_]"
        },
        {
          "description": "binary coded mask, represent min begin",
          "name": "begin_mask", "type": "int32"
        },
        {
          "description": "binary coded mask, represent max end",
          "name": "end_mask", "type": "int32"
        },
        {
          "description": "binary coded mask, represent ... in numpy.slice",
          "name": "ellipsis_mask", "type": "int32"
        },
        {
          "description": "binary coded mask, represent newaxis in numpy.slice",
          "name": "new_axis_mask", "type": "int32"
        },
        {
          "description": "binary coded mask, represent shrink axis then output",
          "name": "shrink_axis_mask", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "sub",
    "schema": {
      "category": "Tensor",
      "description": "`y = lhs - rhs`. Support broadcast.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "lhs",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "rhs",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] `lhs - rhs`",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "tanh",
    "schema": {
      "category": "Activation",
      "description": "Return \frac{exp(x)-exp(-x)}{exp(x)+exp(-x)}, equals 2 * sigmoid(2 * x) - 1.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y.shape == x.shape.",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "tile",
    "schema": {
      "category": "Transform",
      "description": "y = numpy.tile(x, repeats)",
      "attributes": [
        {
          "description": "repeats.size == x.dims, repeat x on each repeat axis.",
          "name": "repeats", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] y = numpy.tile(x, repeats).",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "to_float",
    "schema": {
      "category": "Custom",
      "description": "Cast input to `float32`.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "float32[...]"
        }
      ]
    }
  },
  {
    "name": "topkv2",
    "schema": {
      "category": "Tensor",
      "description": "Get top `number` max values and indices on the last dimension.",
      "attributes": [
        {
          "description": "number of output values and indices on the last dimension.",
          "name": "number", "type": "int32"
        },
        {
          "description": "if sort all outputs by scores.",
          "name": "sorted", "type": "bool", "default": false
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "values",
          "type": "tensor"
        },
        {
          "description": "[device]",
          "name": "indices",
          "type": "int[...]"
        }
      ]
    }
  },
  {
    "name": "transpose_conv2d",
    "schema": {
      "category": "Layer",
      "description": "Do inverse 2D Convolution.",
      "attributes": [
        {
          "description": "in [NCHW, NHWC]",
          "name": "format", "type": "string", "default": "NCHW"
        },
        {
          "description": "",
          "name": "padding", "type": "int32[4, 2]", "default": [0, 0, 0, 0, 0, 0, 0, 0]
        },
        {
          "description": "",
          "name": "padding_value", "type": "float32", "default": 0
        },
        {
          "description": "",
          "name": "stride", "type": "int32[4]", "default": [1, 1, 1, 1]
        },
        {
          "description": "",
          "name": "dilation", "type": "int32[4]", "default": [1, 1, 1, 1]
        }
      ],
      "inputs": [
        {
          "description": "[device] compuating data, in NCHW(default) or NHWC format.",
          "name": "x",
          "type": "[N, _, _, _]"
        },
        {
          "description": "[device] convolution kernel: [output_channels, input_channels, kernel_height, kernel_width].",
          "name": "w",
          "type": "[_, _, _, _]"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "[N, _, _, _]"
        }
      ],
      "examples": [
        {
          "code": "pad_h = pad_h_top + pad_h_bottom\npad_w = pad_w_left + pad_h_right\noutput_h = floor((height + pad_h -\n            (dilation_h * (kernel_h - 1) + 1)) / stride_h + 1);\noutput_w = floor((width + pad_w -\n            (dilation_w * (kernel_w - 1) + 1)) / stride_w + 1);\n",
          "summary": "output shape"
        }
      ]
    }
  },
  {
    "name": "unsqueeze",
    "schema": {
      "category": "Shape",
      "description": "Expand dimensions with 1, representing numpy.expend_dims(x, axis) for axis in axes.",
      "attributes": [
        {
          "description": "axes to expand.",
          "name": "axes", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "yolo",
    "schema": {
      "category": "Layer",
      "description": "Equals to darknet yolo cpu layer forward.",
      "attributes": [
        {
          "description": "number of classes.",
          "name": "classes", "type": "int32"
        },
        {
          "description": "number of classes.",
          "name": "mask", "type": "int32[_]"
        },
        {
          "description": "number of classes.",
          "name": "anchors", "type": "float32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device]",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device] shape is [batch, maks.size * (classes + 4 + 1), h, w]",
          "name": "y",
          "type": "tensor"
        },
        {
          "description": "[host]",
          "name": "classes",
          "type": "int32"
        },
        {
          "description": "[host]",
          "name": "mask",
          "type": "int32[_]"
        },
        {
          "description": "[host]",
          "name": "anchors",
          "type": "float32[_]"
        }
      ],
      "examples": [
        {
          "summary": "yolo[cpu]",
          "code": "template<typename T>\nstatic void compute_run(layer l) {\n    int b, n;\n    auto data = reinterpret_cast<T *>(l.output);\n    for (b = 0; b < l.batch; ++b) {\n        for (n = 0; n < l.n; ++n) {\n            int index = entry_index(l, b, n * l.w * l.h, 0);\n            activate_array<T>(data + index, 2 * l.w * l.h);\n            index = entry_index(l, b, n * l.w * l.h, 4);\n            activate_array<T>(data + index, (1 + l.classes) * l.w * l.h);\n        }\n    }\n}"
        }
      ]
    }
  },
  {
    "name": "yolo_poster",
    "schema": {
      "category": "Tensor",
      "description": "Post process after yolo output to bindingbox.",
      "attributes": [
        {
          "description": "axes to expand.",
          "name": "axes", "type": "int32[_]"
        }
      ],
      "inputs": [
        {
          "description": "[device] net input data",
          "name": "x",
          "type": "tensor"
        },
        {
          "description": "[device] yolo output packed tensors",
          "name": "yolo",
          "type": "tensor",
          "option": "variadic"
        }
      ],
      "outputs": [
        {
          "description": "[host] shape is [N, M]. N is number of bbox. M = 6, representing 4(box: x, y, w, h) + 1(prob) + 1(label). All coordinates in [0, 1].",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_field",
    "schema": {
      "category": "Custom",
      "description": "Get field from packed tensor.",
      "attributes": [
        {
          "description": "offset of packed tensor.",
          "name": "offset", "type": "int32"
        }
      ],
      "inputs": [
        {
          "description": "[device] packed tensor",
          "name": "x",
          "type": "tensor"
        }
      ],
      "outputs": [
        {
          "description": "[device]",
          "name": "field",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "_pack",
    "schema": {
      "category": "Custom",
      "description": "Pack input tensors.",
      "attributes": [],
      "inputs": [
        {
          "description": "[device] list of tensors",
          "name": "tensors",
          "type": "list[tensor]",
          "option": "variadic"
        }
      ],
      "outputs": [
        {
          "description": "[device] output tensor",
          "name": "y",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "<param>",
    "schema": {
      "category": "Data",
      "description": "Import parameter",
      "attributes": [],
      "inputs": [],
      "outputs": [
        {
          "description": "[device] input parameter.",
          "name": "param",
          "type": "tensor"
        }
      ]
    }
  },
  {
    "name": "<const>",
    "schema": {
      "category": "Data",
      "description": "Constant value.",
      "attributes": [
        {
          "description": "constant value.",
          "name": "value", "type": "tensor"
        }
      ],
      "inputs": [],
      "outputs": [
        {
          "description": "[device] const value",
          "name": "const",
          "type": "tensor"
        }
      ]
    }
  }
]
